{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity-embedding-rossmann \n",
    "\n",
    "This is a Pytorch implementation with sklearn model interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'HE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-de24488ce223>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m             'State': 6})\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-entity-embedding-rossmann/EntEmbNN2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_cuda\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-entity-embedding-rossmann/EntEmbNN2.py\u001b[0m in \u001b[0;36miterate_n_epochs\u001b[0;34m(self, epochs)\u001b[0m\n\u001b[1;32m    413\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_transform_inverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-entity-embedding-rossmann/EntEmbNN2.py\u001b[0m in \u001b[0;36meval_model\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m~/pytorch-entity-embedding-rossmann/EntEmbNN2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, log_scale, format_X)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\t[%s] loss_train:%s loss_test:%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         msg_params = (\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m             \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pytorch-entity-embedding-rossmann/EntEmbNN2.py\u001b[0m in \u001b[0;36mmake_dataloader\u001b[0;34m(self, X, y, shuffle, num_workers)\u001b[0m\n\u001b[1;32m    146\u001b[0m             self.X.shape, self.y.shape)\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         X_train, X_test, y_train, y_test = train_test_split(\n\u001b[1;32m    150\u001b[0m             self.X, self.y, train_size=self.train_size)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    572\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    574\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'HE'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datasets\n",
    "import eval_utils\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "import EntEmbNN2 as eenn\n",
    "\n",
    "X_train, y_train, X_test, y_test = datasets.get_X_train_test_data()\n",
    "\n",
    "for data in [X_train, X_test]:\n",
    "    data.drop('Open', inplace=True, axis=1)\n",
    "\n",
    "models = []\n",
    "for _ in range(5):\n",
    "    m = eenn.EntEmbNNRegression(\n",
    "        X_y_test = (X_test, y_test),\n",
    "        cat_emb_dim={\n",
    "            'Store': 10,\n",
    "            'DayOfWeek': 6,\n",
    "            'Promo': 1,\n",
    "            'Year': 2,\n",
    "            'Month': 6,\n",
    "            'Day': 10,\n",
    "            'State': 6})\n",
    "    \n",
    "    m.fit(X_train, y_train)\n",
    "    models.append(m)\n",
    "    print('\\n')\n",
    "\n",
    "test_y_pred = np.array([model.predict(X_test) for model in models])\n",
    "test_y_pred = test_y_pred.mean(axis=0)\n",
    "\n",
    "print('MAPE: %s' % eval_utils.MAPE(\n",
    "    y_true=y_test.values.flatten(),\n",
    "    y_pred=test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original output from repo code:\n",
    "    \n",
    "`\n",
    "Using TensorFlow backend.\n",
    "Number of samples used for training: 200000\n",
    "Fitting NN_with_EntityEmbedding...\n",
    "Train on 200000 samples, validate on 84434 samples\n",
    "Epoch 1/10\n",
    "200000/200000 [==============================] - 13s 64us/step - loss: 0.0142 - val_loss: 0.0119\n",
    "Epoch 2/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0096 - val_loss: 0.0109\n",
    "Epoch 3/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0089 - val_loss: 0.0113\n",
    "Epoch 4/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0082 - val_loss: 0.0101\n",
    "Epoch 5/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0077 - val_loss: 0.0101\n",
    "Epoch 6/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0074 - val_loss: 0.0100\n",
    "Epoch 7/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0072 - val_loss: 0.0099\n",
    "Epoch 8/10\n",
    "200000/200000 [==============================] - 12s 59us/step - loss: 0.0071 - val_loss: 0.0096\n",
    "Epoch 9/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0069 - val_loss: 0.0092\n",
    "Epoch 10/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0068 - val_loss: 0.0095\n",
    "Result on validation data:  0.10152226095724903\n",
    "Train on 200000 samples, validate on 84434 samples\n",
    "Epoch 1/10\n",
    "200000/200000 [==============================] - 13s 63us/step - loss: 0.0140 - val_loss: 0.0117\n",
    "Epoch 2/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0093 - val_loss: 0.0107\n",
    "Epoch 3/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0084 - val_loss: 0.0109\n",
    "Epoch 4/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0079 - val_loss: 0.0096\n",
    "Epoch 5/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0076 - val_loss: 0.0097\n",
    "Epoch 6/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0074 - val_loss: 0.0097\n",
    "Epoch 7/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0072 - val_loss: 0.0097\n",
    "Epoch 8/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0070 - val_loss: 0.0093\n",
    "Epoch 9/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0069 - val_loss: 0.0094\n",
    "Epoch 10/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0068 - val_loss: 0.0093\n",
    "Result on validation data:  0.10194501967184522\n",
    "Train on 200000 samples, validate on 84434 samples\n",
    "Epoch 1/10\n",
    "200000/200000 [==============================] - 13s 64us/step - loss: 0.0141 - val_loss: 0.0121\n",
    "Epoch 2/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0093 - val_loss: 0.0100\n",
    "Epoch 3/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0084 - val_loss: 0.0098\n",
    "Epoch 4/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0079 - val_loss: 0.0095\n",
    "Epoch 5/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0076 - val_loss: 0.0098\n",
    "Epoch 6/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0074 - val_loss: 0.0097\n",
    "Epoch 7/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0072 - val_loss: 0.0098\n",
    "Epoch 8/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0071 - val_loss: 0.0092\n",
    "Epoch 9/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0070 - val_loss: 0.0093\n",
    "Epoch 10/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0069 - val_loss: 0.0097\n",
    "Result on validation data:  0.10076855799458961\n",
    "Train on 200000 samples, validate on 84434 samples\n",
    "Epoch 1/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0141 - val_loss: 0.0114\n",
    "Epoch 2/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0093 - val_loss: 0.0105\n",
    "Epoch 3/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0084 - val_loss: 0.0108\n",
    "Epoch 4/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0079 - val_loss: 0.0099\n",
    "Epoch 5/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0076 - val_loss: 0.0098\n",
    "Epoch 6/10\n",
    "200000/200000 [==============================] - 12s 60us/step - loss: 0.0074 - val_loss: 0.0099\n",
    "Epoch 7/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0072 - val_loss: 0.0100\n",
    "Epoch 8/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0071 - val_loss: 0.0095\n",
    "Epoch 9/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0070 - val_loss: 0.0096\n",
    "Epoch 10/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0068 - val_loss: 0.0099\n",
    "Result on validation data:  0.10973501886112967\n",
    "Train on 200000 samples, validate on 84434 samples\n",
    "Epoch 1/10\n",
    "200000/200000 [==============================] - 13s 63us/step - loss: 0.0144 - val_loss: 0.0116\n",
    "Epoch 2/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0094 - val_loss: 0.0109\n",
    "Epoch 3/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0084 - val_loss: 0.0103\n",
    "Epoch 4/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0079 - val_loss: 0.0099\n",
    "Epoch 5/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0076 - val_loss: 0.0104\n",
    "Epoch 6/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0074 - val_loss: 0.0099\n",
    "Epoch 7/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0072 - val_loss: 0.0099\n",
    "Epoch 8/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0070 - val_loss: 0.0099\n",
    "Epoch 9/10\n",
    "200000/200000 [==============================] - 12s 62us/step - loss: 0.0069 - val_loss: 0.0097\n",
    "Epoch 10/10\n",
    "200000/200000 [==============================] - 12s 61us/step - loss: 0.0068 - val_loss: 0.0100\n",
    "Result on validation data:  0.10491748954856149\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "X_train, y_train, X_test, y_test = datasets.get_X_train_test_data()\n",
    "dtrain = xgb.DMatrix(\n",
    "    X_train.apply(lambda x: x.cat.codes),\n",
    "    label=np.log(y_train))\n",
    "evallist = [(dtrain, 'train')]\n",
    "param = {'nthread': 12,\n",
    "         'max_depth': 7,\n",
    "         'eta': 0.02,\n",
    "         'silent': 1,\n",
    "         'objective': 'reg:linear',\n",
    "         'colsample_bytree': 0.7,\n",
    "         'subsample': 0.7}\n",
    "\n",
    "num_round = 3000\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, verbose_eval=False)\n",
    "\n",
    "xgb_test_y_pred = bst.predict(\n",
    "    xgb.DMatrix(X_test.apply(lambda x: x.cat.codes))\n",
    ")\n",
    "xgb_test_y_pred = np.exp((xgb_test_y_pred))\n",
    "print('MAPE: %s' % eval_utils.MAPE(\n",
    "    y_true=y_test, \n",
    "    y_pred=xgb_test_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original output from repo code:\n",
    "\n",
    "`\n",
    ".\n",
    ".\n",
    ".\n",
    "[2987]  train-rmse:0.148847\n",
    "[2988]  train-rmse:0.148845\n",
    "[2989]  train-rmse:0.148842\n",
    "[2990]  train-rmse:0.148839\n",
    "[2991]  train-rmse:0.148834\n",
    "[2992]  train-rmse:0.148819\n",
    "[2993]  train-rmse:0.148768\n",
    "[2994]  train-rmse:0.148762\n",
    "[2995]  train-rmse:0.148741\n",
    "[2996]  train-rmse:0.148705\n",
    "[2997]  train-rmse:0.148667\n",
    "[2998]  train-rmse:0.148622\n",
    "[2999]  train-rmse:0.148584\n",
    "Result on validation data:  0.14691216270195093\n",
    "`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
